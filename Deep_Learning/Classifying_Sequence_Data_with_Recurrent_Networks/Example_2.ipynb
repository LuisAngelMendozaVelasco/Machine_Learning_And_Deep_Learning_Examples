{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Signal Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates the signals into a datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(\"../data/flooddata/*/*.csv\", shuffle=False)\n",
    "train_dataset = train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in train_dataset:\n",
    "    files.append(file.numpy().astype(str)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used a Dataset to access the files. To train a network that can classify our signals, our data needs to be labeled. The location of these labels will depend on our data set.\n",
    "Each signal in the flood data set is stored in a folder according to its class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depth_0_0', 'depth_0_0', 'depth_0_0', 'depth_0_0', 'depth_0_0', ..., 'depth_4_5', 'depth_4_5', 'depth_4_5', 'depth_4_5', 'depth_4_5']\n",
       "Length: 222\n",
       "Categories (4, object): ['depth_0_0', 'depth_0_19', 'depth_2_5', 'depth_4_5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for file in files:\n",
    "    labels.append(file.split(\"\\\\\")[3])\n",
    "labels = pd.Categorical(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable labels contains a categorical vector. We can use the [value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html#pandas-series-value-counts) function with categorical data to see what labels are our data set and the number of signals per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth_0_0      33\n",
       "depth_0_19     53\n",
       "depth_2_5      34\n",
       "depth_4_5     102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wou can see the number of signals in each class. The class labels come from the subfolder names, which correspond to the depth of water that the volunteer walked through while their smartphone data was recorded.\n",
    "When we classify with our trained deep network, these are the classes that the network will use. We might want to make changes to the labels before training our network. For example, we can combine similar classes into one class. For the flood data set, using the class names below could be more descriptive. We can rename the classes with the [rename_categories()](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.rename_categories.html#pandas-series-cat-rename-categories) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0 ft', '0.0 ft', '0.0 ft', '0.0 ft', '0.0 ft', ..., '4.5 ft', '4.5 ft', '4.5 ft', '4.5 ft', '4.5 ft']\n",
       "Length: 222\n",
       "Categories (4, object): ['0.0 ft', '0.19 ft', '2.5 ft', '4.5 ft']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.rename_categories([\"0.0 ft\", \"0.19 ft\", \"2.5 ft\", \"4.5 ft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depth_0_0' 'depth_0_19' 'depth_2_5' 'depth_4_5'] [  0  33  86 120]\n"
     ]
    }
   ],
   "source": [
    "u, indices = np.unique(labels, return_index=True)\n",
    "print(u, indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
